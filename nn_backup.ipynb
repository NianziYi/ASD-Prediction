{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.io import arff\n",
    "from io import BytesIO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Datasets - Adolescent\n",
    "### Read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1_Score</th>\n",
       "      <th>A2_Score</th>\n",
       "      <th>A3_Score</th>\n",
       "      <th>A4_Score</th>\n",
       "      <th>A5_Score</th>\n",
       "      <th>A6_Score</th>\n",
       "      <th>A7_Score</th>\n",
       "      <th>A8_Score</th>\n",
       "      <th>A9_Score</th>\n",
       "      <th>A10_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>jundice</th>\n",
       "      <th>austim</th>\n",
       "      <th>contry_of_res</th>\n",
       "      <th>used_app_before</th>\n",
       "      <th>result</th>\n",
       "      <th>age_desc</th>\n",
       "      <th>relation</th>\n",
       "      <th>Class/ASD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'm'</td>\n",
       "      <td>b'Hispanic'</td>\n",
       "      <td>b'yes'</td>\n",
       "      <td>b'yes'</td>\n",
       "      <td>b'Austria'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>6.0</td>\n",
       "      <td>b'12-16 years'</td>\n",
       "      <td>b'Parent'</td>\n",
       "      <td>b'NO'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'm'</td>\n",
       "      <td>b'Black'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'Austria'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'12-16 years'</td>\n",
       "      <td>b'Relative'</td>\n",
       "      <td>b'NO'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'?'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'AmericanSamoa'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>b'12-16 years'</td>\n",
       "      <td>b'?'</td>\n",
       "      <td>b'NO'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'White-European'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'United Kingdom'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b'12-16 years'</td>\n",
       "      <td>b'Self'</td>\n",
       "      <td>b'YES'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'1'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>b'0'</td>\n",
       "      <td>...</td>\n",
       "      <td>b'f'</td>\n",
       "      <td>b'?'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>b'Albania'</td>\n",
       "      <td>b'no'</td>\n",
       "      <td>7.0</td>\n",
       "      <td>b'12-16 years'</td>\n",
       "      <td>b'?'</td>\n",
       "      <td>b'YES'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1_Score A2_Score A3_Score A4_Score A5_Score A6_Score A7_Score A8_Score  \\\n",
       "0     b'0'     b'0'     b'0'     b'1'     b'1'     b'1'     b'1'     b'1'   \n",
       "1     b'0'     b'0'     b'0'     b'0'     b'0'     b'0'     b'0'     b'0'   \n",
       "2     b'0'     b'0'     b'0'     b'0'     b'0'     b'0'     b'0'     b'0'   \n",
       "3     b'0'     b'1'     b'1'     b'1'     b'1'     b'1'     b'0'     b'1'   \n",
       "4     b'1'     b'1'     b'1'     b'1'     b'1'     b'1'     b'1'     b'0'   \n",
       "\n",
       "  A9_Score A10_Score  ...  gender          ethnicity jundice  austim  \\\n",
       "0     b'1'      b'0'  ...    b'm'        b'Hispanic'  b'yes'  b'yes'   \n",
       "1     b'1'      b'1'  ...    b'm'           b'Black'   b'no'   b'no'   \n",
       "2     b'1'      b'1'  ...    b'f'               b'?'   b'no'   b'no'   \n",
       "3     b'1'      b'0'  ...    b'f'  b'White-European'   b'no'   b'no'   \n",
       "4     b'0'      b'0'  ...    b'f'               b'?'   b'no'   b'no'   \n",
       "\n",
       "       contry_of_res used_app_before result        age_desc     relation  \\\n",
       "0         b'Austria'           b'no'    6.0  b'12-16 years'    b'Parent'   \n",
       "1         b'Austria'           b'no'    2.0  b'12-16 years'  b'Relative'   \n",
       "2   b'AmericanSamoa'           b'no'    2.0  b'12-16 years'         b'?'   \n",
       "3  b'United Kingdom'           b'no'    7.0  b'12-16 years'      b'Self'   \n",
       "4         b'Albania'           b'no'    7.0  b'12-16 years'         b'?'   \n",
       "\n",
       "  Class/ASD  \n",
       "0     b'NO'  \n",
       "1     b'NO'  \n",
       "2     b'NO'  \n",
       "3    b'YES'  \n",
       "4    b'YES'  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read file\n",
    "data = arff.loadarff('Autism-Adolescent-Data.arff')\n",
    "df_adol = pd.DataFrame(data[0])\n",
    "\n",
    "df_adol = df_adol.drop(['ethnicity', 'contry_of_res', 'age_desc'], axis=1)\n",
    "\n",
    "for key in df_adol.columns.values.tolist():                \n",
    "    if (type(df_adol[key][0])==bytes):                     \n",
    "        df_adol[key] = df_adol[key].str.decode('utf-8')\n",
    "\n",
    "df_adol['gender'] = df_adol['gender'].map({'m': 0, 'f': 1})\n",
    "df_adol['jundice'] = df_adol['jundice'].map({'no': 0, 'yes': 1})\n",
    "df_adol['austim'] = df_adol['austim'].map({'no': 0, 'yes': 1})\n",
    "df_adol['used_app_before'] = df_adol['used_app_before'].map({'no': 0, 'yes': 1})\n",
    "df_adol['relation'] = df_adol['relation'].map({'Parent': 0, 'Self': 1, 'Relative': 2, 'Health care professional': 3, 'Others':4, '?': 0})\n",
    "df_adol['Class/ASD'] = df_adol['Class/ASD'].map({'NO': 0, 'YES': 1})\n",
    "\n",
    "for key in df_adol.columns.values.tolist():        # loop though all entries           \n",
    "    if (type(df_adol[key][0]) != int):             # Find non int data\n",
    "        df_adol[key] = df_adol[key].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, max_age=16, normalize=False):\n",
    "        if normalize:\n",
    "            if 'age' in X.index:\n",
    "                X['age'] /= max_age;\n",
    "            X *= 2\n",
    "            X -= 1\n",
    "        self.data = torch.from_numpy(X.to_numpy()).type(torch.float)\n",
    "        self.label = torch.from_numpy(y.to_numpy()).type(torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim=17, hidden_dim=100):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        data, label = next(iter(loader))\n",
    "        scores = model(data)\n",
    "        _, preds = scores.max(1)\n",
    "        num_correct = (preds == label).sum()\n",
    "        num_samples = preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "def train(model, optimizer, criterion, dataloader, epochs=100, print_every=10):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    for e in range(epochs):\n",
    "        data, label = next(iter(dataloader))\n",
    "        model.train() \n",
    "\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, label)\n",
    "\n",
    "        # Zero out all of the gradients for the variables which the optimizer\n",
    "        # will update.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # This is the backwards pass: compute the gradient of the loss with\n",
    "        # respect to each  parameter of the model.\n",
    "        loss.backward()\n",
    "\n",
    "        # Actually update the parameters of the model using the gradients\n",
    "        # computed by the backwards pass.\n",
    "        optimizer.step()\n",
    "\n",
    "        if (e+1) % print_every == 0:\n",
    "            print('Iteration %d, loss = %.4f' % (e, loss.item()))\n",
    "            check_accuracy(dataloader, model)\n",
    "            print()\n",
    "\n",
    "def test_accuracy(model, x, y, max_age=16, normalize=False):\n",
    "    if normalize:\n",
    "        if 'age' in x.index:\n",
    "            x['age'] /= max_age\n",
    "        x *= 2\n",
    "        x -= 1\n",
    "    data = torch.from_numpy(x.to_numpy()).type(torch.float)\n",
    "    label = torch.from_numpy(y.to_numpy()).type(torch.long)\n",
    "    scores = model(data)\n",
    "    _, preds = scores.max(1)\n",
    "    num_correct = (preds == label).sum()\n",
    "    num_samples = preds.size(0)\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f) on test set' % (num_correct, num_samples, 100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.5467\n",
      "Got 41 / 64 correct (64.06)\n",
      "\n",
      "Iteration 19, loss = 0.5393\n",
      "Got 41 / 64 correct (64.06)\n",
      "\n",
      "Iteration 29, loss = 0.5357\n",
      "Got 43 / 64 correct (67.19)\n",
      "\n",
      "Iteration 39, loss = 0.4509\n",
      "Got 43 / 64 correct (67.19)\n",
      "\n",
      "Iteration 49, loss = 0.4203\n",
      "Got 47 / 64 correct (73.44)\n",
      "\n",
      "Iteration 59, loss = 0.4455\n",
      "Got 51 / 64 correct (79.69)\n",
      "\n",
      "Iteration 69, loss = 0.4285\n",
      "Got 52 / 64 correct (81.25)\n",
      "\n",
      "Iteration 79, loss = 0.3784\n",
      "Got 53 / 64 correct (82.81)\n",
      "\n",
      "Iteration 89, loss = 0.3697\n",
      "Got 52 / 64 correct (81.25)\n",
      "\n",
      "Iteration 99, loss = 0.3272\n",
      "Got 55 / 64 correct (85.94)\n",
      "\n",
      "Got 28 / 32 correct (87.50) on test set\n"
     ]
    }
   ],
   "source": [
    "# train_data = torch.from_numpy(X_train)\n",
    "# test_data = torch.from_numpy(X_test)\n",
    "# Split to data and labels\n",
    "X = df_adol.copy().drop(['Class/ASD'], axis=1)\n",
    "y = df_adol.copy()['Class/ASD']\n",
    "labels_to_drop = []\n",
    "# ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'result']\n",
    "X = X.drop(labels=labels_to_drop, axis=1)\n",
    "\n",
    "# train-test-split\n",
    "normalize = True\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "dataset = CustomDataset(X_train, y_train,normalize=normalize)\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "input_dim = len(X_train.columns.values)\n",
    "hidden_dim = 100\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        )\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n",
    "\n",
    "train(model, optimizer, criterion, train_dataloader, epochs=epochs)\n",
    "test_accuracy(model, X_test, y_test, normalize=normalize)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 0.7307\n",
      "Got 29 / 64 correct (45.31)\n",
      "\n",
      "Iteration 20, loss = 0.4462\n",
      "Got 56 / 64 correct (87.50)\n",
      "\n",
      "Iteration 40, loss = 0.2382\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 60, loss = 0.1254\n",
      "Got 63 / 64 correct (98.44)\n",
      "\n",
      "Iteration 80, loss = 0.0706\n",
      "Got 63 / 64 correct (98.44)\n",
      "\n",
      "Iteration 100, loss = 0.0555\n",
      "Got 64 / 64 correct (100.00)\n",
      "\n",
      "Iteration 120, loss = 0.0398\n",
      "Got 64 / 64 correct (100.00)\n",
      "\n",
      "Iteration 140, loss = 0.0276\n",
      "Got 64 / 64 correct (100.00)\n",
      "\n",
      "Iteration 160, loss = 0.0228\n",
      "Got 64 / 64 correct (100.00)\n",
      "\n",
      "Iteration 180, loss = 0.0166\n",
      "Got 64 / 64 correct (100.00)\n",
      "\n",
      "Iteration 200, loss = 0.0140\n",
      "Got 64 / 64 correct (100.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_data = torch.from_numpy(X_train)\n",
    "# test_data = torch.from_numpy(X_test)\n",
    "# Split to data and labels\n",
    "X = df_adol.copy().drop(['Class/ASD'], axis=1)\n",
    "y = df_adol.copy()['Class/ASD']\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "labels_to_drop = ['result', 'austim', 'used_app_before', 'age', 'gender', 'jundice', 'relation']\n",
    "#['result', 'austim', 'used_app_before', 'age', 'gender', 'jundice', 'relation']\n",
    "# ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'result']\n",
    "X_train = X_train.drop(labels=labels_to_drop, axis=1)\n",
    "dataset = CustomDataset(X_train, y_train,normalize=False)\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "batch_size = 64\n",
    "num_batchs = 100\n",
    "input_dim = len(X_train.columns.values)\n",
    "hidden_dim = 100\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        )\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n",
    "\n",
    "train(model, optimizer, criterion, train_dataloader, epochs=201, print_every=20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 499, loss = 0.2117\n",
      "Got 58 / 64 correct (90.62)\n",
      "\n",
      "Iteration 999, loss = 0.1945\n",
      "Got 59 / 64 correct (92.19)\n",
      "\n",
      "Iteration 1499, loss = 0.1593\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 1999, loss = 0.1454\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 2499, loss = 0.1486\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 2999, loss = 0.1180\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 3499, loss = 0.1449\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 3999, loss = 0.1405\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n",
      "Iteration 4499, loss = 0.1390\n",
      "Got 61 / 64 correct (95.31)\n",
      "\n",
      "Iteration 4999, loss = 0.1318\n",
      "Got 60 / 64 correct (93.75)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train_data = torch.from_numpy(X_train)\n",
    "# test_data = torch.from_numpy(X_test)\n",
    "# Split to data and labels\n",
    "X = df_adol.copy().drop(['Class/ASD'], axis=1)\n",
    "y = df_adol.copy()['Class/ASD']\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "labels_to_drop = ['result', 'austim', 'used_app_before', 'age', 'gender', 'jundice', 'relation', 'A2_Score', 'A1_Score', 'A7_Score', 'A8_Score']\n",
    "#['result', 'austim', 'used_app_before', 'age', 'gender', 'jundice', 'relation']\n",
    "# ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'result']\n",
    "X_train = X_train.drop(labels=labels_to_drop, axis=1)\n",
    "dataset = CustomDataset(X_train, y_train,normalize=False)\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "epochs = 5000\n",
    "print_every = epochs/10\n",
    "input_dim = len(X_train.columns.values)\n",
    "hidden_dim = 200\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 2)\n",
    "        )\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n",
    "\n",
    "train(model, optimizer, criterion, train_dataloader, epochs=epochs, print_every=print_every)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataLiteracy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e4fe21159920ef1afdcef415185e445783315a71f8876a74f7d58c00a6c547c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
