{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.io import arff\n",
    "from io import BytesIO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Datasets - Adolescent\n",
    "### 1. Read data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file\n",
    "data = arff.loadarff('Autism-Adolescent-Data.arff')\n",
    "df_adol = pd.DataFrame(data[0])\n",
    "df_adol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data type of each feature in the dataset\n",
    "df_adol.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_adol.columns.values.tolist():                # loop through all entries of the dataframe\n",
    "    if (type(df_adol[key][0])==bytes):                     # find bytes object\n",
    "        df_adol[key] = df_adol[key].str.decode('utf-8')   # Decode and replace\n",
    "df_adol.head()                                             # check"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the number of Non-ASD/ASD children in different age groups\n",
    "CrosstabResult_age = pd.crosstab(index = df_adol['age'],columns = df_adol['Class/ASD'], rownames=['Age'])\n",
    "CrosstabResult_gender = pd.crosstab(index = df_adol['gender'],columns = df_adol['Class/ASD'], rownames=['Gender'])\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(12,5))\n",
    "CrosstabResult_age.plot.bar(ax = ax[0])\n",
    "ax[0].set_ylabel(\"Counts\")\n",
    "ax[0].set_title(\"Non-ASD/ASD Adolescents in Different Age Groups\")\n",
    "plt.sca(ax[0])\n",
    "plt.xticks(ticks=range(len(np.unique(df_adol['age'].astype(int)))), labels=np.unique(df_adol['age'].astype(int)),rotation=0)\n",
    "plt.yticks(ticks=[0,5,10,15,20], labels=[0,5,10,15,20])\n",
    "for bar in ax[0].patches:\n",
    "    y_value = bar.get_height()\n",
    "    x_value = bar.get_x() + bar.get_width() / 2\n",
    "    space = 1\n",
    "    label = format(y_value)\n",
    "    ax[0].annotate(label, (x_value, y_value), xytext=(0, space), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "\n",
    "CrosstabResult_gender.plot.bar(ax = ax[1])\n",
    "ax[1].set_title(\"Non-ASD/ASD Adolescents in Different Gender Groups\")\n",
    "plt.sca(ax[1])\n",
    "plt.xticks([0,1], ['Female', 'Male'], rotation=0)\n",
    "for bar in ax[1].patches:\n",
    "    y_value = bar.get_height()\n",
    "    x_value = bar.get_x() + bar.get_width() / 2\n",
    "    space = 1\n",
    "    label = format(y_value)\n",
    "    ax[1].annotate(label, (x_value, y_value), xytext=(0, space), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Remove the entries, which we are not interessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adol = df_adol.drop(['ethnicity', 'contry_of_res', 'age_desc'], axis=1)\n",
    "df_adol.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_adol.columns.values.tolist():\n",
    "    print(key + \" has value: \", df_adol[key].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adol['gender'] = df_adol['gender'].map({'m': 0, 'f': 1})\n",
    "df_adol['jundice'] = df_adol['jundice'].map({'no': 0, 'yes': 1})\n",
    "df_adol['austim'] = df_adol['austim'].map({'no': 0, 'yes': 1})\n",
    "df_adol['used_app_before'] = df_adol['used_app_before'].map({'no': 0, 'yes': 1})\n",
    "df_adol['relation'] = df_adol['relation'].map({'Parent': 0, 'Self': 1, 'Relative': 2, 'Health care professional': 3, 'Others':4, '?': 0})\n",
    "df_adol['Class/ASD'] = df_adol['Class/ASD'].map({'NO': 0, 'YES': 1})\n",
    "df_adol.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Handle missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adol[df_adol.isna().sum(axis=1) > 0] # Find whcih columns have missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the data are string not int, we will change it here\n",
    "for key in df_adol.columns.values.tolist():        # loop though all entries           \n",
    "    if (type(df_adol[key][0]) != int):             # Find non int data\n",
    "        df_adol[key] = df_adol[key].astype(int)    # Change it to int\n",
    "\n",
    "# Check dtype again\n",
    "df_adol.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Check the size and balance of processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Number of Non_ASD samples in the dataset: {}\".format(len(df_adol[df_adol['Class/ASD'] == 0]))\n",
    ")\n",
    "print(\n",
    "    \"Number of ASD samples in the dataset: {}\".format(len(df_adol[df_adol['Class/ASD'] == 1]))\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Randoom Forest Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Split the data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to data and labels\n",
    "X = df_adol.copy().drop(['Class/ASD'], axis=1)\n",
    "y = df_adol.copy()['Class/ASD']\n",
    "\n",
    "# train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(\"Size of Training Set: \", len(X_train))\n",
    "print(\"Size of Testing Set: \", len(X_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat a random forest model\n",
    "model = RandomForestClassifier(n_estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalute RF Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy on testing set:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity Check\n",
    "y_fake = np.random.choice([0,1], y_train.shape)   # Change the result to random numbers\n",
    "print(\"Accuracy with fake results:\",sklearn.metrics.accuracy_score(model.predict(X_train), y_fake))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sklearn.metrics.f1_score(y_test, y_pred)\n",
    "print('F1 Score: ', f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['No ASD', 'ASD'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model.feature_importances_\n",
    "index = np.argsort(model.feature_importances_).tolist()\n",
    "index.reverse\n",
    "std = np.std([tree.feature_importances_[index] for tree in model.estimators_], axis=0)\n",
    "for idx in index:\n",
    "    print(X_train.columns[idx], \": \", importance[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bar chart of sorted features\n",
    "plt.barh(X_train.columns[index], model.feature_importances_[index], color=['green'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"RF Feature Importance\")\n",
    "plt.ylabel(\"Feature Name\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models with limited features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use only \"result\" to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_drop = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', \n",
    "'austim', 'used_app_before', 'age', 'gender', 'jundice', 'relation']\n",
    "n_estimator = 100\n",
    "X_drop = X.drop(labels=labels_to_drop, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_drop, y, test_size=0.3)\n",
    "model = RandomForestClassifier(n_estimators=n_estimator)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Dropped features: \", labels_to_drop)\n",
    "print(\"Used features\", X_drop.columns.values.tolist())\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['No ASD', 'ASD'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use the 10 questions A1 to A10 to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_drop = ['result', 'austim', 'used_app_before', 'age', 'gender', 'jundice', 'relation']\n",
    "n_estimator = 500\n",
    "X_drop = X.drop(labels=labels_to_drop, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_drop, y, test_size=0.2)\n",
    "model = RandomForestClassifier(n_estimators=n_estimator)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Dropped features: \", labels_to_drop)\n",
    "print(\"Used features\", X_drop.columns.values.tolist())\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "importance = model.feature_importances_\n",
    "index = np.argsort(importance).tolist()\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.barh(X_train.columns[index], importance[index], color=\"green\")\n",
    "#plt.xticks(rotation=90)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['No ASD', 'ASD'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use features unrelated to AQ10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_drop = ['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'result']\n",
    "n_estimator = 500\n",
    "X_drop = X.drop(labels=labels_to_drop, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_drop, y, test_size=0.2)\n",
    "model = RandomForestClassifier(n_estimators=n_estimator)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Dropped features: \", labels_to_drop)\n",
    "print(\"Used features\", X_drop.columns.values.tolist())\n",
    "print(\"Accuracy:\",sklearn.metrics.accuracy_score(y_test, y_pred))\n",
    "importance = model.feature_importances_\n",
    "index = np.argsort(importance).tolist()\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.barh(X_train.columns[index], importance[index], color=\"green\")\n",
    "#plt.xticks(rotation=90)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "disp = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = ['No ASD', 'ASD'])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "k = np.count_nonzero(y_test==y_pred)\n",
    "n = len(y_pred)\n",
    "print(\"Null hypothsis: The model trained on features unrelated to AQ10 is only guessing the result.\")\n",
    "print(\"Altenative hypothsis: The modle is not only guessing the result\")\n",
    "print(\"If the model is only guessing, for each result, it has 50\\% chance to get the correct answer.\")\n",
    "print(\"The number of correct answer follows a binomial distribution B(21,0.5)\")\n",
    "p = stats.binomtest(k,n,1/2).pvalue\n",
    "print(\"The model achieved an accuracy of {:.1f}%.\".format(sklearn.metrics.accuracy_score(y_test, y_pred)*100))\n",
    "print(\"P-Value of the result is {}.\".format(p))\n",
    "print(\"We can not reject the null hypothesis that the model is only guessing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataLiteracy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 | packaged by conda-forge | (main, Oct 24 2022, 16:02:16) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e4fe21159920ef1afdcef415185e445783315a71f8876a74f7d58c00a6c547c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
